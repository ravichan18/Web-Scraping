{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Project - End of the Day Stock data (EODData)\n",
    "\n",
    "Data Source : [EODDATA - End of the Day Stock data](http://eoddata.com/stocklist/TSX/A.htm)\n",
    "![](https://i.imgur.com/rWt0W74.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Web Scraping \n",
    "\n",
    ">### Q1. What is Web Scraping?\n",
    "In the most simple terms, **Web Scraping** is the process through which we extract data from a website, and save it in a form which is easy to read, to understand and to work on. \n",
    "\n",
    ">When we say 'Easy to work on', we mean to say that the data thus extracted can be used to get a lot of useful insights and answer a lot of questions, finding answers to which would not be such an easy task, if we did not have that data stored with us in a simple and sorted manner, i.e. generally in a `CSV File, an Excel File or a Database`.\n",
    "\n",
    ">### Q2. How does web scraping work?\n",
    "![](https://i.imgur.com/iv6RhmW.png)\n",
    "\n",
    ">To understand web scraping, it’s important to first understand that web pages are built with text-based mark-up languages – the most common being `HTML`.\n",
    "\n",
    ">A mark-up language defines the structure of a website’s content. Since there are universal components and tags of mark-up languages, this makes it much easier for web scrapers to pull all the information that it needs.\n",
    "Once the HTML is parsed, the scraper then extracts the necessary data and stores it.  \n",
    "**Note**  : Not all websites allow Web Scraping, especially when personal information of the users is involved, so we should always ensure that we do not explore too much, and don't get our hands on information which might belong to someone else.\n",
    "Websites generally have protections at place, and they would block our access to the website if they see us scraping a large amount of data from their website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About EODData\n",
    "\n",
    "![](https://i.imgur.com/sOQ7li5.png)\n",
    "\n",
    "EODData provides free quality end of day stock market data to traders with wide range of exchanges, data formats, tools and services.The website also provides historical data with minimum monthly fee.\n",
    "\n",
    "The website also have a variety of servers that are dedicated to finding and correcting the numerous errors that stock exchanges produce. All of our historical data has been carefully screened and adjusted for splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Idea\n",
    "\n",
    "As part of this project, we will parse through the EODData website to get the details for Toronto Stock Exchange information.\n",
    "\n",
    "We will retrieve information from the page **’Toronto Stock Exchange’** using _web scraping_: a process of extracting information from a website programmatically. For this specific project we will be scraping stocks starting with Alphabets A to H."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goal\n",
    "\n",
    "The project goal is to build a web scraper that withdraws stock information and assemble them into a single CSV. The format of the output CSV file is shown below:\n",
    "\n",
    "|#|Code|Name|High|Low|Close|Volume|Stock Page URL\n",
    "|-|----------|-------|---------------|-----|------|-----------------|-----------\n",
    "|1|AAB|Aberdeen International Inc|0.1400|0.1350|0.1400|13138|http://eoddata.com/stockquote/TSX/AAB.htm\n",
    "|2|AAV|Advantage Oil & Gas Ltd|6.370|6.130|6.360|684302|http://eoddata.com/stockquote/TSX/AAV.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project steps\n",
    "Here is an outline of the steps we'll follow :\n",
    "\n",
    "1. Download the webpage using `requests`\n",
    "2. Parse the HTML source code using `BeautifulSoup` library and extract the desired infromation\n",
    "3. Building the scraper components\n",
    "4. Compile the extracted information into Python list and dictionaries\n",
    "5. Converting the python dictionaries into `Pandas DataFrames`\n",
    "5. Write information to the final CSV file\n",
    "7. Future work and references\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Packages Used:\n",
    ">1. Requests — For downloading the HTML code from the IMDB URL\n",
    ">2. BeautifulSoup4 — For parsing and extracting data from the HTML string\n",
    ">3. Pandas — to gather my data into a dataframe for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run the code\n",
    "\n",
    "This tutorial is an executable [Jupyter notebook](https://jupyter.org) hosted on [Jovian](https://www.jovian.ai). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
    "\n",
    "#### Option 1: Running using free online resources (1-click, recommended)\n",
    "\n",
    "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.\n",
    "\n",
    "\n",
    "#### Option 2: Running on your computer locally\n",
    "\n",
    "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
    "\n",
    ">  **Jupyter Notebooks**: This tutorial is a [Jupyter notebook](https://jupyter.org) - a document made of _cells_. Each cell can contain code written in Python or explanations in plain English. You can execute code cells and view the results, e.g., numbers, messages, graphs, tables, files, etc., instantly within the notebook. Jupyter is a powerful platform for experimentation and analysis. Don't be afraid to mess around with the code & break things - you'll learn a lot by encountering and fixing errors. You can use the \"Kernel > Restart & Clear Output\" menu option to clear all outputs and start again from the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note : We will use the `Jovian` library and its `commit()` function throughout the code to save our progress as we move along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"ivarchan/final-web-scraping-project\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/ivarchan/final-web-scraping-project\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/ivarchan/final-web-scraping-project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "import jovian\n",
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"final-web-scraping-project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the webpage using `requests`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### **What is `requests`**\n",
    "\n",
    "\n",
    ">Requests is a Python HTTP library that allows us to send HTTP requests to servers of websites, instead of using browsers to communicate the web.\n",
    "\n",
    ">We use `pip`, a package-management system, to install and manage softwares. Since the platform we selected is **Binder**, we would have to type a line of code `!pip install` to install `requests`. You will see lots codes of `!pip` when installing other packages.\n",
    "\n",
    ">When we attempt to use some prewritten functions from a certain library, we would use the `import` statement. e.g. When we would have to type `import requests` after installation, we are able to use any function from `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --quiet --upgrade\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **requests.get()**\n",
    "\n",
    "In order to **download a web page**, we use `requests.get()` to **send the HTTP request** to the **IMDB server** and what the function returns is a **response object**, which is **the HTTP response**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ssV51Yc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_url = 'http://eoddata.com/stocklist/TSX/A.htm'   #The URL Address of the webpage we will scrape, i.e. Stocks starting from A\n",
    "response = requests.get(home_url)      #requests.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Status code**\n",
    "\n",
    "Now, we have to `check` if we succesfully send the HTTP request and get a HTTP response back on purpose. This is because we're NOT using browsers, because of which we can't get `the feedback` directly if we didn't send HTTP requests successfully.\n",
    "\n",
    "In general, the method to check out if the server sended a HTTP response back is the **status code**. In `requests` library, `requests.get` returns a response object, which containing the page contents and the information about status code indicating if the HTTP request was successful. Learn more about HTTP status codes here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status.\n",
    "\n",
    "\n",
    "If the request was successful, `response.status_code` is set to a value between **200 and 299**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code    #Here we are checking the Status code, -> 200-299 will mean that the request was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTTP response contains HTML that is ready to be displayed in browser. Here we can use `response.text` to retrive the HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112462"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents = response.text\n",
    "len(page_contents)    #The `len` fucnction tells us the length of the response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\r\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\r\\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\\r\\n<head><link rel=\"stylesheet\" href=\"../../styles/jquery-ui-1.10.0.custom.min.css\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"../../styles/main.css\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"../../styles/button.css\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"../../styles/nav.css\" type=\"text/css\" />\\r\\n  <script src=\"/scripts/jquery-1.9.0.min.js\" type=\"text/javascript\"></script>\\r\\n  <script src=\"/scripts/jquery-ui-1.10.0.custom.min.js\" type=\"text/javascript\"></script>\\r\\n\\t<script type=\"text/javascript\">\\t\\tvar _sf_startpt = (new Date()).getTime()</script>\\r\\n  \\r\\n\\t<script type=\"text/javascript\" src=\"scripts/jquery-1.4.2.min.js\"></script>\\r\\n<meta name=\"keywords\" content=\"list of symbols for Toronto Stock Exchange,list of stock symbols,download symbols,stock symbols list,TSX symbol list,TSX stock ticker,TSX stock list,T'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:1000]   #This displays the first 1000 characters of `page_contents`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What we see above is the source code of the web page. It is written in a language called HTML. \n",
    "- It defines and display the content and structure of the web page by the help of the browsers like Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"ivarchan/final-web-scraping-project\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/ivarchan/final-web-scraping-project\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/ivarchan/final-web-scraping-project'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit() #Saving the work done till now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using Beautiful Soup library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### What is Beautiful Soup?\n",
    "\n",
    ">Beautiful Soup is **a Python package** for **parsing HTML and XML documents**. Beautiful Soup enables us to get data out of sequences of characters. It creates a parse tree for parsed pages that can be used to extract data from HTML. It's a handy tool when it comes to web scraping. You can read more on their documentation site. https://www.crummy.com/software/BeautifulSoup/bs4/doc/#getting-help\n",
    "\n",
    ">To extract information from the HTML source code of a webpage programmatically, we can use the Beautiful Soup library. Let's install the library and import **the BeautifulSoup class** from **the bs4 module.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --quiet --upgrade\n",
    "from bs4 import BeautifulSoup\n",
    "doc = BeautifulSoup(page_contents, 'html.parser')  #Now 'doc' contains entire html in parsed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the HTML source code of a web page\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In Beautiful Soup library, we can specify `html.parser` to ask Python to read components of the page, instead of reading it as a long string. \n",
    "\n",
    ">### What is HTML?\n",
    "Before we dive into how to inspect HTML, we should know the basic knowledge about HTML.\n",
    "\n",
    ">The HyperText Markup Language, or HTML is the standard markup language for documents designed to be displayed in a web browser. It can be assisted by technologies such as Cascading Style Sheets and scripting languages such as JavaScript.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ChftiDR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **An HTML tag comprises of three parts:**\n",
    "\n",
    "1. **Name**: (`html`, `head`, `body`, `div`, etc.) Indicates what the tag represents and how a browser should interpret the information inside it.\n",
    "2. **Attributes**: (`href`, `target`, `class`, `id`, etc.) Properties of tag used by the browser to customize how a tag is displayed and decide what happens on user interactions.\n",
    "3. **Children**: A tag can contain some text or other tags or both between the opening and closing segments, e.g., `<div>Some content</div>`.\n",
    "\n",
    "\n",
    "### Common tags and attributes\n",
    "\n",
    "#### **Tags in HTML**\n",
    "\n",
    "There are around 100 types of HTML tags but on a day to day basis, around 15 to 20 of them are the most common use, such as `<div>` tag, `<p>` tag, `<section>` tag, `<img>` tag, `<a>` tags.\n",
    "\n",
    "\n",
    "Of many tags, I wanted to highlight **`<a>` tag**, which  can contain attributes such as `href` (hyperlink reference), because `<a>` tag allows users to click and they would be directed to another site. That's why the name of `<a>` tag is  **anchor**.\n",
    "\n",
    "#### **Attributes**\n",
    "\n",
    "Each tag supports several attributes. Following are some common attributes used to modify the behavior of tags\n",
    "\n",
    "* `id`\n",
    "* `style`\n",
    "* `class`\n",
    "* `href` (used with `<a>`)\n",
    "* `src` (used with `<img>`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What we can do with **a BeautifulSoup object** is to get **a specifc types of a tag in HTML** by calling the name of a tag, as shown in code cell below.`\n",
    "\n",
    "Here, we use the `find()` function of BeautifulSoup to find the first `<title>` tag in the HTML document and display its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>\n",
       "\tList of Symbols for Toronto Stock Exchange [TSX] Starting with A\n",
       "</title>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = doc.find('title')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting HTML in the Browser\n",
    "\n",
    ">To view the **source code** of any webpage right within **your browser**, you can **right click** anywhere on a page and **select** the **\"Inspect\"** option. You access the **\"Developer Tools\"** mode, where you can see the source code as **a tree**. You can expand and collapse various nodes and find the source code for a specific portion of the page\n",
    "\n",
    "![](https://i.imgur.com/ByuBJbA.png)\n",
    "\n",
    "\n",
    "As shown in the photo above, I've cursored over one of the Stock to display how the entire content was presented. \n",
    "I found out that each `stock` was present inside the `<tr>` tag.\n",
    "\n",
    "Since I've pulled a single page and return to a BeautifulSoup object, we can start to use some function from Beautiful Soup library to withdraw the piece of information we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we get the main tr tag for complete stock information. Note we have alternate stocks so getting both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_parent1 = doc.find_all('tr',{'class':'ro'}) \n",
    "tr_parent2 = doc.find_all('tr',{'class':'re'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like we have around 120 records for stocks starting with 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_parent1) + len(tr_parent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets get the indivdual td for the first stock which has all the information required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_child1 = tr_parent1[0].find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td><a href=\"/stockquote/TSX/AAB.htm\" title=\"Display Quote &amp; Chart for TSX,AAB\">AAB</a></td>,\n",
       " <td>Aberdeen International Inc</td>,\n",
       " <td align=\"right\">0.1350</td>,\n",
       " <td align=\"right\">0.1300</td>,\n",
       " <td align=\"right\">0.1300</td>,\n",
       " <td align=\"right\">146,215</td>,\n",
       " <td align=\"right\">-0.0050</td>,\n",
       " <td align=\"center\"><img src=\"/images/dn.gif\"/></td>,\n",
       " <td align=\"left\">3.70</td>,\n",
       " <td align=\"right\"><a href=\"/stockquote/TSX/AAB.htm\" title=\"Download Data for TSX,AAB\"><img height=\"14\" src=\"/images/dl.gif\" width=\"14\"/></a> <a href=\"/stockquote/TSX/AAB.htm\" title=\"View Quote and Chart for TSX,AAB\"><img height=\"14\" src=\"/images/chart.gif\" width=\"14\"/></a></td>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_child1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the individual information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = td_child1[0].find('a').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = td_child1[1].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = td_child1[2].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = td_child1[3].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closing value of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = td_child1[4].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total volume of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = td_child1[5].text.strip().replace(',', '') # Here we remove the comma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://eoddata.com/\" + td_child1[0].find('a')['href'] # Here we append the base url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print all the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: AAB\n",
      "Name: Aberdeen International Inc\n",
      "High: 0.1350\n",
      "Low: 0.1300\n",
      "Volume: 146215\n",
      "URL: http://eoddata.com//stockquote/TSX/AAB.htm\n"
     ]
    }
   ],
   "source": [
    "print(\"Symbol:\", format(symbol))\n",
    "print(\"Name:\", format(name))\n",
    "print(\"High:\", format(high))\n",
    "print(\"Low:\", format(low))\n",
    "print(\"Volume:\", format(volume))\n",
    "print(\"URL:\", format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the generic function with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(tr_tag):\n",
    "    \n",
    "    td_tag = tr_tag.find_all('td')\n",
    "    symbol = td_tag[0].find('a').text.strip()\n",
    "    name = td_tag[1].text.strip()\n",
    "    high = td_tag[2].text.strip()\n",
    "    low = td_tag[3].text.strip()\n",
    "    close = td_tag[4].text.strip()\n",
    "    volume = td_tag[5].text.strip().replace(',', '')\n",
    "    url = \"http://eoddata.com/\" + td_child1[0].find('a')['href']\n",
    "    \n",
    "    print(\"Symbol:\", format(symbol))\n",
    "    print(\"Name:\", format(name))\n",
    "    print(\"High:\", format(high))\n",
    "    print(\"Low:\", format(low))\n",
    "    print(\"Volume:\", format(volume))\n",
    "    print(\"URL:\", format(url))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test the function by for specific stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: ABST\n",
      "Name: Absolute Software Corp\n",
      "High: 11.65\n",
      "Low: 11.10\n",
      "Volume: 186919\n",
      "URL: http://eoddata.com//stockquote/TSX/AAB.htm\n"
     ]
    }
   ],
   "source": [
    "parse_document(tr_parent1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: AD.UN\n",
      "Name: Alaris Equity Partners Income Trust\n",
      "High: 18.26\n",
      "Low: 17.92\n",
      "Volume: 98156\n",
      "URL: http://eoddata.com//stockquote/TSX/AAB.htm\n"
     ]
    }
   ],
   "source": [
    "parse_document(tr_parent1[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's update the function to return dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(tr_tag):\n",
    "    \n",
    "    td_tag = tr_tag.find_all('td')\n",
    "    symbol = td_tag[0].find('a').text.strip()\n",
    "    name = td_tag[1].text.strip()\n",
    "    high = td_tag[2].text.strip()\n",
    "    low = td_tag[3].text.strip()\n",
    "    close = td_tag[4].text.strip()\n",
    "    volume = td_tag[5].text.strip().replace(',', '')\n",
    "    url = \"http://eoddata.com/\" + td_tag[0].find('a')['href']\n",
    "    \n",
    "    # Return a dictionary\n",
    "    return {\n",
    "        'Symbol': symbol,\n",
    "        'Name': name,        \n",
    "        'High': high,\n",
    "        'Low': low,\n",
    "        'Close': close,\n",
    "        'Volume': volume,\n",
    "        'URL': url\n",
    "    }   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use the above function to get all the stock information of the given page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records_1 = [parse_document(tag) for tag in tr_parent1]\n",
    "all_records_2 = [parse_document(tag) for tag in tr_parent2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_records_1) + len(all_records_2) # The length the page records matches with the len we found earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combine both the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = [item for sublist in zip(all_records_1, all_records_2) for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing information to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(items, path):\n",
    "    # Open the file in write mode\n",
    "    with open(path, 'w') as f:\n",
    "        # Return if there's nothing to write\n",
    "        if len(items) == 0:\n",
    "            return\n",
    "        \n",
    "        # Write the headers in the first line\n",
    "        headers = list(items[0].keys())\n",
    "        f.write(','.join(headers) + '\\n')\n",
    "        \n",
    "        # Write one item per line\n",
    "        for item in items:\n",
    "            values = []\n",
    "            for header in headers:\n",
    "                values.append(str(item.get(header, \"\")))\n",
    "            f.write(','.join(values) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(all_records,\"A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAB</td>\n",
       "      <td>Aberdeen International Inc</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>146215</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AAB.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAV</td>\n",
       "      <td>Advantage Oil &amp; Gas Ltd</td>\n",
       "      <td>6.630</td>\n",
       "      <td>6.060</td>\n",
       "      <td>6.610</td>\n",
       "      <td>2106233</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AAV.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCT</td>\n",
       "      <td>ABC Technologies Holdings Inc</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.550</td>\n",
       "      <td>5.790</td>\n",
       "      <td>4029</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABCT.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCT.RT</td>\n",
       "      <td>ABC Technologies Holdings Inc Rights</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>58102</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABCT.RT.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABST</td>\n",
       "      <td>Absolute Software Corp</td>\n",
       "      <td>11.650</td>\n",
       "      <td>11.100</td>\n",
       "      <td>11.130</td>\n",
       "      <td>186919</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABST.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>AX.PR.E</td>\n",
       "      <td>Artis REIT Pref Ser E</td>\n",
       "      <td>24.350</td>\n",
       "      <td>24.250</td>\n",
       "      <td>24.300</td>\n",
       "      <td>3300</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.PR.E.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>AX.PR.I</td>\n",
       "      <td>Artis REIT Pref Series I</td>\n",
       "      <td>25.660</td>\n",
       "      <td>25.400</td>\n",
       "      <td>25.660</td>\n",
       "      <td>1269</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.PR.I.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>AX.UN</td>\n",
       "      <td>Artis Real Estate Investment Trust Units</td>\n",
       "      <td>13.130</td>\n",
       "      <td>12.930</td>\n",
       "      <td>13.020</td>\n",
       "      <td>308738</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.UN.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>AXU</td>\n",
       "      <td>Alexco Resource Corp</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.820</td>\n",
       "      <td>1.930</td>\n",
       "      <td>162738</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AXU.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>AYA</td>\n",
       "      <td>Aya Gold and Silver Inc</td>\n",
       "      <td>10.550</td>\n",
       "      <td>9.860</td>\n",
       "      <td>10.360</td>\n",
       "      <td>543086</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AYA.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol                                      Name    High     Low  \\\n",
       "0        AAB                Aberdeen International Inc   0.135   0.130   \n",
       "1        AAV                   Advantage Oil & Gas Ltd   6.630   6.060   \n",
       "2       ABCT             ABC Technologies Holdings Inc   5.790   5.550   \n",
       "3    ABCT.RT      ABC Technologies Holdings Inc Rights   0.010   0.005   \n",
       "4       ABST                    Absolute Software Corp  11.650  11.100   \n",
       "..       ...                                       ...     ...     ...   \n",
       "115  AX.PR.E                     Artis REIT Pref Ser E  24.350  24.250   \n",
       "116  AX.PR.I                  Artis REIT Pref Series I  25.660  25.400   \n",
       "117    AX.UN  Artis Real Estate Investment Trust Units  13.130  12.930   \n",
       "118      AXU                      Alexco Resource Corp   1.950   1.820   \n",
       "119      AYA                   Aya Gold and Silver Inc  10.550   9.860   \n",
       "\n",
       "      Close   Volume                                             URL  \n",
       "0     0.130   146215      http://eoddata.com//stockquote/TSX/AAB.htm  \n",
       "1     6.610  2106233      http://eoddata.com//stockquote/TSX/AAV.htm  \n",
       "2     5.790     4029     http://eoddata.com//stockquote/TSX/ABCT.htm  \n",
       "3     0.005    58102  http://eoddata.com//stockquote/TSX/ABCT.RT.htm  \n",
       "4    11.130   186919     http://eoddata.com//stockquote/TSX/ABST.htm  \n",
       "..      ...      ...                                             ...  \n",
       "115  24.300     3300  http://eoddata.com//stockquote/TSX/AX.PR.E.htm  \n",
       "116  25.660     1269  http://eoddata.com//stockquote/TSX/AX.PR.I.htm  \n",
       "117  13.020   308738    http://eoddata.com//stockquote/TSX/AX.UN.htm  \n",
       "118   1.930   162738      http://eoddata.com//stockquote/TSX/AXU.htm  \n",
       "119  10.360   543086      http://eoddata.com//stockquote/TSX/AYA.htm  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('A.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/NlQftOh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final function with all the information above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_stockInfo(alpha_list):  \n",
    "    base_url = \"http://eoddata.com/stocklist/TSX/\"\n",
    "    \n",
    "    for i in range(len(alpha_list)):\n",
    "        data_url = base_url + alpha_list[i] +\".htm\"\n",
    "        response = requests.get(data_url)\n",
    "        page_contents = response.text\n",
    "        doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "        tr_tags1 = doc.find_all('tr',{'class':'ro'})\n",
    "        tr_tags2 = doc.find_all('tr',{'class':'re'})\n",
    "        all_records_1 = [parse_document(tag) for tag in tr_tags1]\n",
    "        all_records_2 = [parse_document(tag) for tag in tr_tags2]\n",
    "        all_records = [item for sublist in zip(all_records_1, all_records_2) for item in sublist]\n",
    "        \n",
    "        file_name = alpha_list[i] + \".csv\"\n",
    "        write_csv(all_records,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create separate csv for each alphabet across multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = ['A','B','D','E','F','G','H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap_stockInfo(alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5rNA8M3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>Hydro One Ltd</td>\n",
       "      <td>31.21</td>\n",
       "      <td>30.770</td>\n",
       "      <td>30.92</td>\n",
       "      <td>1238299</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/H.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAB</td>\n",
       "      <td>Horizons Active Corporate Bond ETF</td>\n",
       "      <td>10.47</td>\n",
       "      <td>10.440</td>\n",
       "      <td>10.47</td>\n",
       "      <td>2705</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HAB.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAC</td>\n",
       "      <td>Horizons Seasonal Rotation ETF</td>\n",
       "      <td>25.55</td>\n",
       "      <td>25.270</td>\n",
       "      <td>25.31</td>\n",
       "      <td>4568</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HAC.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAD</td>\n",
       "      <td>Horizons Active CDN Bond ETF</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.730</td>\n",
       "      <td>9.73</td>\n",
       "      <td>1055</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HAD.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAEB</td>\n",
       "      <td>Horizons Active ESG Corporate Bond ETF</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.460</td>\n",
       "      <td>9.46</td>\n",
       "      <td>323</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HAEB.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>HYI</td>\n",
       "      <td>Horizons Active High Yield Bond ETF</td>\n",
       "      <td>8.77</td>\n",
       "      <td>8.560</td>\n",
       "      <td>8.68</td>\n",
       "      <td>13927</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYI.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>HYLD</td>\n",
       "      <td>Hamilton Enhanced U.S. Covered Call ETF</td>\n",
       "      <td>16.03</td>\n",
       "      <td>15.670</td>\n",
       "      <td>15.67</td>\n",
       "      <td>159908</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYLD.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>HYLD.U</td>\n",
       "      <td>Hamilton Enhanced US Coverd Call ETF USD</td>\n",
       "      <td>15.95</td>\n",
       "      <td>15.700</td>\n",
       "      <td>15.70</td>\n",
       "      <td>5626</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYLD.U.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>HZD</td>\n",
       "      <td>Betapro Silver 2X Daily Bear ETF</td>\n",
       "      <td>18.57</td>\n",
       "      <td>18.100</td>\n",
       "      <td>18.10</td>\n",
       "      <td>22030</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HZD.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>HZM</td>\n",
       "      <td>Horizonte Minerals Plc</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2603800</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HZM.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol                                      Name   High     Low  Close  \\\n",
       "0         H                             Hydro One Ltd  31.21  30.770  30.92   \n",
       "1       HAB        Horizons Active Corporate Bond ETF  10.47  10.440  10.47   \n",
       "2       HAC            Horizons Seasonal Rotation ETF  25.55  25.270  25.31   \n",
       "3       HAD              Horizons Active CDN Bond ETF   9.78   9.730   9.73   \n",
       "4      HAEB    Horizons Active ESG Corporate Bond ETF   9.46   9.460   9.46   \n",
       "..      ...                                       ...    ...     ...    ...   \n",
       "167     HYI       Horizons Active High Yield Bond ETF   8.77   8.560   8.68   \n",
       "168    HYLD   Hamilton Enhanced U.S. Covered Call ETF  16.03  15.670  15.67   \n",
       "169  HYLD.U  Hamilton Enhanced US Coverd Call ETF USD  15.95  15.700  15.70   \n",
       "170     HZD          Betapro Silver 2X Daily Bear ETF  18.57  18.100  18.10   \n",
       "171     HZM                    Horizonte Minerals Plc   0.11   0.105   0.11   \n",
       "\n",
       "      Volume                                            URL  \n",
       "0    1238299       http://eoddata.com//stockquote/TSX/H.htm  \n",
       "1       2705     http://eoddata.com//stockquote/TSX/HAB.htm  \n",
       "2       4568     http://eoddata.com//stockquote/TSX/HAC.htm  \n",
       "3       1055     http://eoddata.com//stockquote/TSX/HAD.htm  \n",
       "4        323    http://eoddata.com//stockquote/TSX/HAEB.htm  \n",
       "..       ...                                            ...  \n",
       "167    13927     http://eoddata.com//stockquote/TSX/HYI.htm  \n",
       "168   159908    http://eoddata.com//stockquote/TSX/HYLD.htm  \n",
       "169     5626  http://eoddata.com//stockquote/TSX/HYLD.U.htm  \n",
       "170    22030     http://eoddata.com//stockquote/TSX/HZD.htm  \n",
       "171  2603800     http://eoddata.com//stockquote/TSX/HZM.htm  \n",
       "\n",
       "[172 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('H.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we can created csv for each stock starting with the Alphabets, let's combine everything and remove the individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create empty list\n",
    "final_list = []\n",
    " \n",
    "# append individual csv into the list\n",
    "for i in range(len(alpha_list)):\n",
    "    temp_df = pd.read_csv(alpha_list[i]+\".csv\")\n",
    "    os.remove(alpha_list[i]+\".csv\")\n",
    "    final_list.append(temp_df)\n",
    "    \n",
    "# create new data frame with the combined list\n",
    "merged_df = pd.concat(final_list,axis=0, ignore_index=True)\n",
    "\n",
    "# export into final csv\n",
    "merged_df.to_csv( \"Toronto_Stocks.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/vEHvvoc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check few records in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 976 entries, 0 to 975\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Symbol  976 non-null    object \n",
      " 1   Name    976 non-null    object \n",
      " 2   High    976 non-null    float64\n",
      " 3   Low     976 non-null    float64\n",
      " 4   Close   976 non-null    float64\n",
      " 5   Volume  976 non-null    int64  \n",
      " 6   URL     976 non-null    object \n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 53.5+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAB</td>\n",
       "      <td>Aberdeen International Inc</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>146215</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AAB.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAV</td>\n",
       "      <td>Advantage Oil &amp; Gas Ltd</td>\n",
       "      <td>6.630</td>\n",
       "      <td>6.060</td>\n",
       "      <td>6.610</td>\n",
       "      <td>2106233</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AAV.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCT</td>\n",
       "      <td>ABC Technologies Holdings Inc</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.550</td>\n",
       "      <td>5.790</td>\n",
       "      <td>4029</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABCT.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCT.RT</td>\n",
       "      <td>ABC Technologies Holdings Inc Rights</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>58102</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABCT.RT.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABST</td>\n",
       "      <td>Absolute Software Corp</td>\n",
       "      <td>11.650</td>\n",
       "      <td>11.100</td>\n",
       "      <td>11.130</td>\n",
       "      <td>186919</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABST.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABTC</td>\n",
       "      <td>Accelerate Carbon Negative Bitcoin ETF</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.840</td>\n",
       "      <td>3.840</td>\n",
       "      <td>200</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABTC.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABTC.U</td>\n",
       "      <td>Accelerate Carbon Neg Bitcoin ETF USD</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>16100</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABTC.U.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABX</td>\n",
       "      <td>Barrick Gold Corp</td>\n",
       "      <td>29.470</td>\n",
       "      <td>28.850</td>\n",
       "      <td>29.110</td>\n",
       "      <td>4830196</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ABX.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AC</td>\n",
       "      <td>Air Canada</td>\n",
       "      <td>25.980</td>\n",
       "      <td>24.710</td>\n",
       "      <td>24.910</td>\n",
       "      <td>5230236</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AC.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACB</td>\n",
       "      <td>Aurora Cannabis Inc</td>\n",
       "      <td>5.150</td>\n",
       "      <td>4.750</td>\n",
       "      <td>4.760</td>\n",
       "      <td>1566158</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/ACB.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol                                    Name    High     Low   Close  \\\n",
       "0      AAB              Aberdeen International Inc   0.135   0.130   0.130   \n",
       "1      AAV                 Advantage Oil & Gas Ltd   6.630   6.060   6.610   \n",
       "2     ABCT           ABC Technologies Holdings Inc   5.790   5.550   5.790   \n",
       "3  ABCT.RT    ABC Technologies Holdings Inc Rights   0.010   0.005   0.005   \n",
       "4     ABST                  Absolute Software Corp  11.650  11.100  11.130   \n",
       "5     ABTC  Accelerate Carbon Negative Bitcoin ETF   3.850   3.840   3.840   \n",
       "6   ABTC.U   Accelerate Carbon Neg Bitcoin ETF USD   3.000   3.000   3.000   \n",
       "7      ABX                       Barrick Gold Corp  29.470  28.850  29.110   \n",
       "8       AC                              Air Canada  25.980  24.710  24.910   \n",
       "9      ACB                     Aurora Cannabis Inc   5.150   4.750   4.760   \n",
       "\n",
       "    Volume                                             URL  \n",
       "0   146215      http://eoddata.com//stockquote/TSX/AAB.htm  \n",
       "1  2106233      http://eoddata.com//stockquote/TSX/AAV.htm  \n",
       "2     4029     http://eoddata.com//stockquote/TSX/ABCT.htm  \n",
       "3    58102  http://eoddata.com//stockquote/TSX/ABCT.RT.htm  \n",
       "4   186919     http://eoddata.com//stockquote/TSX/ABST.htm  \n",
       "5      200     http://eoddata.com//stockquote/TSX/ABTC.htm  \n",
       "6    16100   http://eoddata.com//stockquote/TSX/ABTC.U.htm  \n",
       "7  4830196      http://eoddata.com//stockquote/TSX/ABX.htm  \n",
       "8  5230236       http://eoddata.com//stockquote/TSX/AC.htm  \n",
       "9  1566158      http://eoddata.com//stockquote/TSX/ACB.htm  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>HXT.U</td>\n",
       "      <td>Horizons S&amp;P TSX 60 Index ETF USD</td>\n",
       "      <td>39.20</td>\n",
       "      <td>39.200</td>\n",
       "      <td>39.20</td>\n",
       "      <td>4000</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HXT.U.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>HXU</td>\n",
       "      <td>Betapro S&amp;P TSX 60 2X Daily Bull ETF</td>\n",
       "      <td>20.81</td>\n",
       "      <td>20.280</td>\n",
       "      <td>20.31</td>\n",
       "      <td>104968</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HXU.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>HXX</td>\n",
       "      <td>Horizons Euro Stoxx 50 Index ETF</td>\n",
       "      <td>36.97</td>\n",
       "      <td>36.930</td>\n",
       "      <td>36.97</td>\n",
       "      <td>650</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HXX.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>HYBR</td>\n",
       "      <td>Horizons Active Hybrd Bond Prf Share ETF</td>\n",
       "      <td>9.73</td>\n",
       "      <td>9.670</td>\n",
       "      <td>9.67</td>\n",
       "      <td>11742</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYBR.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>HYDR</td>\n",
       "      <td>Horizons Global Hydrogen Index ETF</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.200</td>\n",
       "      <td>15.20</td>\n",
       "      <td>156</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYDR.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>HYI</td>\n",
       "      <td>Horizons Active High Yield Bond ETF</td>\n",
       "      <td>8.77</td>\n",
       "      <td>8.560</td>\n",
       "      <td>8.68</td>\n",
       "      <td>13927</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYI.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>HYLD</td>\n",
       "      <td>Hamilton Enhanced U.S. Covered Call ETF</td>\n",
       "      <td>16.03</td>\n",
       "      <td>15.670</td>\n",
       "      <td>15.67</td>\n",
       "      <td>159908</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYLD.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>HYLD.U</td>\n",
       "      <td>Hamilton Enhanced US Coverd Call ETF USD</td>\n",
       "      <td>15.95</td>\n",
       "      <td>15.700</td>\n",
       "      <td>15.70</td>\n",
       "      <td>5626</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HYLD.U.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>HZD</td>\n",
       "      <td>Betapro Silver 2X Daily Bear ETF</td>\n",
       "      <td>18.57</td>\n",
       "      <td>18.100</td>\n",
       "      <td>18.10</td>\n",
       "      <td>22030</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HZD.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>HZM</td>\n",
       "      <td>Horizonte Minerals Plc</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2603800</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/HZM.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol                                      Name   High     Low  Close  \\\n",
       "966   HXT.U         Horizons S&P TSX 60 Index ETF USD  39.20  39.200  39.20   \n",
       "967     HXU      Betapro S&P TSX 60 2X Daily Bull ETF  20.81  20.280  20.31   \n",
       "968     HXX          Horizons Euro Stoxx 50 Index ETF  36.97  36.930  36.97   \n",
       "969    HYBR  Horizons Active Hybrd Bond Prf Share ETF   9.73   9.670   9.67   \n",
       "970    HYDR        Horizons Global Hydrogen Index ETF  15.20  15.200  15.20   \n",
       "971     HYI       Horizons Active High Yield Bond ETF   8.77   8.560   8.68   \n",
       "972    HYLD   Hamilton Enhanced U.S. Covered Call ETF  16.03  15.670  15.67   \n",
       "973  HYLD.U  Hamilton Enhanced US Coverd Call ETF USD  15.95  15.700  15.70   \n",
       "974     HZD          Betapro Silver 2X Daily Bear ETF  18.57  18.100  18.10   \n",
       "975     HZM                    Horizonte Minerals Plc   0.11   0.105   0.11   \n",
       "\n",
       "      Volume                                            URL  \n",
       "966     4000   http://eoddata.com//stockquote/TSX/HXT.U.htm  \n",
       "967   104968     http://eoddata.com//stockquote/TSX/HXU.htm  \n",
       "968      650     http://eoddata.com//stockquote/TSX/HXX.htm  \n",
       "969    11742    http://eoddata.com//stockquote/TSX/HYBR.htm  \n",
       "970      156    http://eoddata.com//stockquote/TSX/HYDR.htm  \n",
       "971    13927     http://eoddata.com//stockquote/TSX/HYI.htm  \n",
       "972   159908    http://eoddata.com//stockquote/TSX/HYLD.htm  \n",
       "973     5626  http://eoddata.com//stockquote/TSX/HYLD.U.htm  \n",
       "974    22030     http://eoddata.com//stockquote/TSX/HZD.htm  \n",
       "975  2603800     http://eoddata.com//stockquote/TSX/HZM.htm  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>AX.PR.E</td>\n",
       "      <td>Artis REIT Pref Ser E</td>\n",
       "      <td>24.350</td>\n",
       "      <td>24.25</td>\n",
       "      <td>24.30</td>\n",
       "      <td>3300</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.PR.E.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>AX.PR.I</td>\n",
       "      <td>Artis REIT Pref Series I</td>\n",
       "      <td>25.660</td>\n",
       "      <td>25.40</td>\n",
       "      <td>25.66</td>\n",
       "      <td>1269</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.PR.I.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>AX.UN</td>\n",
       "      <td>Artis Real Estate Investment Trust Units</td>\n",
       "      <td>13.130</td>\n",
       "      <td>12.93</td>\n",
       "      <td>13.02</td>\n",
       "      <td>308738</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AX.UN.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>AXU</td>\n",
       "      <td>Alexco Resource Corp</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.93</td>\n",
       "      <td>162738</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AXU.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>AYA</td>\n",
       "      <td>Aya Gold and Silver Inc</td>\n",
       "      <td>10.550</td>\n",
       "      <td>9.86</td>\n",
       "      <td>10.36</td>\n",
       "      <td>543086</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/AYA.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>BABY</td>\n",
       "      <td>Else Nutrition Holdings Inc</td>\n",
       "      <td>1.170</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.17</td>\n",
       "      <td>53438</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BABY.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>BABY.WT</td>\n",
       "      <td>Else Nutrition Holdings Inc WT</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25000</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BABY.WT.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>BABY.WT.A</td>\n",
       "      <td>Else Nutrition Holdings Inc.</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>13500</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BABY.WT.A.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>BAM.A</td>\n",
       "      <td>Brookfield Asset Management Inc Cl A Lv</td>\n",
       "      <td>68.840</td>\n",
       "      <td>66.60</td>\n",
       "      <td>66.70</td>\n",
       "      <td>1304902</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BAM.A.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BAM.PF.A</td>\n",
       "      <td>Brookfield Asset Mgmt Inc Pref Ser 32</td>\n",
       "      <td>24.850</td>\n",
       "      <td>24.71</td>\n",
       "      <td>24.85</td>\n",
       "      <td>10649</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BAM.PF.A.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>BAM.PF.B</td>\n",
       "      <td>Brookfield Asset Mgmt Inc Pref Ser 34</td>\n",
       "      <td>23.380</td>\n",
       "      <td>23.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>3731</td>\n",
       "      <td>http://eoddata.com//stockquote/TSX/BAM.PF.B.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol                                      Name    High    Low  \\\n",
       "115    AX.PR.E                     Artis REIT Pref Ser E  24.350  24.25   \n",
       "116    AX.PR.I                  Artis REIT Pref Series I  25.660  25.40   \n",
       "117      AX.UN  Artis Real Estate Investment Trust Units  13.130  12.93   \n",
       "118        AXU                      Alexco Resource Corp   1.950   1.82   \n",
       "119        AYA                   Aya Gold and Silver Inc  10.550   9.86   \n",
       "120       BABY               Else Nutrition Holdings Inc   1.170   1.14   \n",
       "121    BABY.WT            Else Nutrition Holdings Inc WT   0.065   0.05   \n",
       "122  BABY.WT.A              Else Nutrition Holdings Inc.   0.210   0.20   \n",
       "123      BAM.A   Brookfield Asset Management Inc Cl A Lv  68.840  66.60   \n",
       "124   BAM.PF.A     Brookfield Asset Mgmt Inc Pref Ser 32  24.850  24.71   \n",
       "125   BAM.PF.B     Brookfield Asset Mgmt Inc Pref Ser 34  23.380  23.20   \n",
       "\n",
       "     Close   Volume                                               URL  \n",
       "115  24.30     3300    http://eoddata.com//stockquote/TSX/AX.PR.E.htm  \n",
       "116  25.66     1269    http://eoddata.com//stockquote/TSX/AX.PR.I.htm  \n",
       "117  13.02   308738      http://eoddata.com//stockquote/TSX/AX.UN.htm  \n",
       "118   1.93   162738        http://eoddata.com//stockquote/TSX/AXU.htm  \n",
       "119  10.36   543086        http://eoddata.com//stockquote/TSX/AYA.htm  \n",
       "120   1.17    53438       http://eoddata.com//stockquote/TSX/BABY.htm  \n",
       "121   0.05    25000    http://eoddata.com//stockquote/TSX/BABY.WT.htm  \n",
       "122   0.20    13500  http://eoddata.com//stockquote/TSX/BABY.WT.A.htm  \n",
       "123  66.70  1304902      http://eoddata.com//stockquote/TSX/BAM.A.htm  \n",
       "124  24.85    10649   http://eoddata.com//stockquote/TSX/BAM.PF.A.htm  \n",
       "125  23.25     3731   http://eoddata.com//stockquote/TSX/BAM.PF.B.htm  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[115:125]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Finally, we have managed to `parse` 'EOD Data website' to get our hands on very **interesting and insightful data** when it comes world of financial stock information.  \n",
    "We have saved all the information we could extract from that website for our needs in a `CSV` file using which we can further get answers to a lot of questions we may want to ask, e.g - `Which stock was best but on the given day`\n",
    "![](https://imgur.com/uAGgHE3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let us look at the steps that we took from start to finish : \n",
    "\n",
    "1. We downloaded the webpage using `requests`  \n",
    "\n",
    "\n",
    "2. We `parsed` the HTML source code using `BeautifulSoup` library and extracted the desired information, i.e.\n",
    "    * Stock Name\n",
    "    * Opening and closing price of each stock\n",
    "\n",
    "\n",
    "3. We extracted detailed information for each stock,such as :\n",
    "    * Stock Symbol\n",
    "    * Stock Name\n",
    "    * Highest price\n",
    "    * Lowest price\n",
    "    * Closing price\t\n",
    "    * Total volumes traded\n",
    "    * URL to get the historical data of the stock\t\n",
    "\n",
    "\n",
    "4. We then created a `Python Dictionary` to save all these details\n",
    "\n",
    "\n",
    "5. We converted the python dictionary into `Pandas DataFrames`\n",
    "\n",
    "\n",
    "6. Then we combined the multiple csv files generated for each alphabets into single data frame and remove others.\n",
    "\n",
    "\n",
    "7. With one single DataFrame in hand, we then converted it into a single `CSV` file, which was the goal of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now work forward to explore this data more and more to fetch meaningful information out of it.  \n",
    "\n",
    "With all the insights , and further analysis into the data, we can have answers to a lot of questions like -   \n",
    "* Which stock performed better on the given day \n",
    "* Which stock traded more based on volume\n",
    "* Individual stock information\n",
    "* Gain/Loss information of the stock\n",
    "\n",
    "And the list goes on..\n",
    "\n",
    "In the future, I would like to work to make this `DataSet` even richer with \n",
    "\n",
    "* Stock information for symbols starting with other alphabets\n",
    "* Scrap the individual stock detail page to get more insights of specific stock\n",
    "* Scrap different exchanges like NASDAQ and others...\n",
    "* Automation script to scrap the stock information on daily basis to generate the data set which can be further used for Exploratory Data Analysis and draw interesting insights for stock market across different exchanges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "[1] Python offical documentation. https://docs.python.org/3/\n",
    "\n",
    "\n",
    "[2] Requests library. https://pypi.org/project/requests/\n",
    "\n",
    "\n",
    "[3] Beautiful Soup documentation. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "\n",
    "[4] Aakash N S, Introduction to Web Scraping, 2021. https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "\n",
    "[5] Pandas library documentation. https://pandas.pydata.org/docs/\n",
    "\n",
    "\n",
    "[6] IMDB Website. https://www.imdb.com/chart/top\n",
    "\n",
    "\n",
    "[7] Web Scraping Article. https://www.toptal.com/python/web-scraping-with-python\n",
    "\n",
    "\n",
    "[8] Web Scraping Image. https://morioh.com/p/431153538ecb\n",
    "\n",
    "[8] Working with Jupyter Notebook https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"ivarchan/final-web-scraping-project\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/ivarchan/final-web-scraping-project\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/ivarchan/final-web-scraping-project'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(files=['Toronto_Stocks.csv'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
